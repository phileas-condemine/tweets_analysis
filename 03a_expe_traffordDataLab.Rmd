---
title: "Reproduce traffordDataLab Medium Article"
output:
  html_document:
    df_print: paged
---

https://medium.com/@traffordDataLab/exploring-tweets-in-r-54f6011a193d

```{r libraries}
library(data.table)
library(rtweet)
library(tidyverse)
library(tidytext)
# remotes::install_github("gadenbuie/tweetrmd")
# remotes::install_github('rstudio/webshot2')
library(Rcpp)
library(tweetrmd)
library(emo)
library(wordcloud) 

```

```{r load data}
tweets=readRDS("data/silver/preprocessed.RDS")
```


```{r show data}
tweets %>% 
  sample_n(5) %>%
  select(created_at, screen_name, text, favorite_count, retweet_count)
```

```{r ts}
ts_plot(tweets, "hours") +
  labs(x = NULL, y = NULL,
       title = "Frequency of tweets with a #ClimateEmergency hashtag",
       subtitle = paste0(format(min(tweets$created_at), "%d %B %Y"), " to ", format(max(tweets$created_at),"%d %B %Y")),
       caption = "Data collected from Twitter's REST API via rtweet") +
  theme_minimal()
```

```{r most retweeted}
most_retweeted = tweets %>% 
  arrange(-retweet_count) %>%
  slice(1) %>% 
  select(created_at, screen_name, text, retweet_count,status_id)

tweet_screenshot(tweet_url(most_retweeted$screen_name, most_retweeted$status_id),file = "img/most_influent_tweet.png")
```


![Most retweeted tweet](img/most_influent_tweet.png "Most retweeted tweet")
```{r most liked}
most_liked = tweets %>% 
  arrange(-favorite_count) %>%
  top_n(5, favorite_count) %>% 
  select(created_at, screen_name, text, favorite_count)
DT::datatable(most_liked)
```

```{r top usernames}
tweets %>% 
  count(screen_name,description, sort = TRUE) %>%
  top_n(10) %>%
  mutate(screen_name = paste0("@", screen_name))
```
```{r emojis}
tweets %>%
  mutate(emoji = emo::ji_extract_all(text)) %>%
  unnest(cols = c(emoji)) %>%
  count(emoji, sort = TRUE) %>%
  top_n(10)%>%DT::datatable()
```



```{r top hashtags}
tweets %>% 
  unnest_tokens(hashtag, text, "tweets", to_lower = FALSE) %>%
  filter(str_detect(hashtag, "^#")) %>%
  count(hashtag, sort = TRUE) %>%
  top_n(10)
```


```{r top mentions}
tweets %>% 
  unnest_tokens(mentions, text, "tweets", to_lower = FALSE) %>%
  filter(str_detect(mentions, "^@")) %>%  
  count(mentions, sort = TRUE) %>%
  top_n(10)
```

```{r top words}
tm_stop_words = tm::stopwords("fr")
tm_stop_words = c("a","cest",tm_stop_words)
words <- tweets %>%
  mutate(text = str_remove_all(text, "&amp;|&lt;|&gt;"),
         text = str_remove_all(text, "\\s?(f|ht)(tp)(s?)(://)([^\\.]*)[\\.|/](\\S*)"),
         text = str_remove_all(text, "[^\x01-\x7F]")) %>% 
  unnest_tokens(word, text, token = "tweets") %>%
  filter(!word %in% tm_stop_words,
        !word %in% str_remove_all(tm_stop_words, "'"),
        str_detect(word, "[a-z]"),
        !str_detect(word, "^#"),         
        !str_detect(word, "@\\S+")) %>%
  count(word, sort = TRUE)
words %>% 
  with(wordcloud(word, n, random.order = FALSE, max.words = 100, colors = "#F29545"))
```

